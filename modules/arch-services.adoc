// Module included in the following assemblies:
//
// * architecture/networking.adoc

[id='services-{context}']
= Services

A Kubernetes link:http://kubernetes.io/docs/user-guide/services[service] serves
as an internal load balancer. It identifies a set of replicated pods
in order to proxy the connections it receives to them. Backing pods can be added
to or removed from a service arbitrarily while the service remains consistently
available, enabling anything that depends on the service to refer to it at a
consistent address.  The default service clusterIP addresses are from the
{product-title} internal network and they are used to permit pods to access each
other.

ifdef::openshift-enterprise,openshift-origin[]
To permit external access to the service, additional `externalIP` and
`ingressIP` addresses that are external
to the cluster can be assigned to the service. These `externalIP` addresses can
also be virtual IP addresses that provide highly available access to the service.
endif::[]

Services are assigned an IP address and port pair that, when accessed,
proxy to an appropriate backing pod. A service uses a label selector to find
all the containers running that provide a certain network service on a certain
port.

Like pods, services are REST objects. The
link:http://kubernetes.io/docs/user-guide/services/[Kubernetes documentation]
has more information on services.

ifdef::openshift-enterprise,openshift-origin[]
[id='service-externalIPs-{context}']
== Service externalIPs

In addition to the cluster's internal IP addresses, the user can configure IP
addresses that are external to the cluster. The administrator is responsible
for ensuring that traffic arrives at a node with this IP.

endif::[]

ifdef::openshift-origin,openshift-enterprise[]
[id='service-ingressIPs-{context}']
== Service ingressIPs

In non-cloud clusters, externalIP addresses can be automatically assigned from a
pool of addresses. This eliminates the need for the administrator manually
assigning them.

endif::[]

ifdef::openshift-origin,openshift-enterprise[]
[id='service-proxy-mode-{context}']
== Service proxy mode

{product-title} has two different implementations of the service-routing
infrastructure. The default implementation is entirely *iptables*-based, and
uses probabilistic *iptables* rewriting rules to distribute incoming service
connections between the endpoint pods. The older implementation uses a user
space process to accept incoming connections and then proxy traffic between the
client and one of the endpoint pods.

The *iptables*-based implementation is much more efficient, but it requires that
all endpoints are always able to accept connections; the user space
implementation is slower, but can try multiple endpoints in turn until it finds
one that works. If you have good readiness
checks (or generally reliable nodes and pods), then the *iptables*-based
service proxy is the best choice. Otherwise, you can enable the user space-based
proxy when installing, or after deploying the cluster by editing the node
configuration file.
endif::[]

ifdef::openshift-online,openshift-dedicated[]
[id='service-proxy-{context}']
== Service proxy

{product-title} has an *iptables*-based implementation of the service-routing
infrastructure. It uses probabilistic *iptables* rewriting rules to distribute
incoming service connections between the endpoint pods. It also requires that
all endpoints are always able to accept connections.
endif::[]